import { neon } from "@neondatabase/serverless"

const sql = neon(process.env.DATABASE_URL!)

// å‹ç¼©é…ç½®å¸¸é‡
const COMPRESSION_INTERVAL = 30 * 60 * 1000 // 30åˆ†é’Ÿï¼ˆæ¯«ç§’ï¼‰
const COMPRESSION_DELAY = 30 * 60 * 1000    // å‹ç¼©30åˆ†é’Ÿå‰çš„æ•°æ®

interface CompressionResult {
  compressed: boolean
  compressedRows: number
  deletedRows: number
  error?: string
}

/**
 * æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰§è¡Œè‡ªåŠ¨å‹ç¼©
 * æ¯30åˆ†é’Ÿæ£€æŸ¥ä¸€æ¬¡ï¼Œå‹ç¼©30åˆ†é’Ÿå‰çš„æ•°æ®
 */
export async function checkAndCompress(): Promise<CompressionResult> {
  try {
    // åˆ›å»ºå‹ç¼©çŠ¶æ€è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    await ensureCompressionStateTable()

    // æ£€æŸ¥æ˜¯å¦åˆ°äº†å‹ç¼©æ—¶é—´
    const shouldCompress = await shouldPerformCompression()
    if (!shouldCompress) {
      return { compressed: false, compressedRows: 0, deletedRows: 0 }
    }

    console.log('ğŸ—œï¸ å¼€å§‹è‡ªåŠ¨æ•°æ®å‹ç¼©...')

    // åˆ›å»ºå‹ç¼©è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    await ensureCompressionTableExists()

    // å‹ç¼©30åˆ†é’Ÿå‰çš„æ•°æ®
    const now = Date.now()
    const compressTime = new Date(now - COMPRESSION_DELAY)
    const result = await compressDataBefore(compressTime)

    // æ›´æ–°å‹ç¼©çŠ¶æ€
    await updateCompressionState()

    console.log(`âœ… è‡ªåŠ¨å‹ç¼©å®Œæˆ: å‹ç¼©${result.compressedRows}è¡Œï¼Œåˆ é™¤${result.deletedRows}è¡Œ`)

    return {
      compressed: true,
      compressedRows: result.compressedRows,
      deletedRows: result.deletedRows
    }

  } catch (error) {
    console.error('âŒ è‡ªåŠ¨å‹ç¼©å¤±è´¥:', error)
    return {
      compressed: false,
      compressedRows: 0,
      deletedRows: 0,
      error: String(error)
    }
  }
}

/**
 * ç¡®ä¿å‹ç¼©çŠ¶æ€è¡¨å­˜åœ¨
 */
async function ensureCompressionStateTable(): Promise<void> {
  await sql`
    CREATE TABLE IF NOT EXISTS compression_state (
      id INTEGER PRIMARY KEY DEFAULT 1,
      last_check_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      last_compression_time TIMESTAMP,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      CONSTRAINT single_row CHECK (id = 1)
    )
  `

  // ç¡®ä¿æœ‰ä¸€æ¡è®°å½•
  await sql`
    INSERT INTO compression_state (id)
    VALUES (1)
    ON CONFLICT (id) DO NOTHING
  `
}

/**
 * æ£€æŸ¥æ˜¯å¦åº”è¯¥æ‰§è¡Œå‹ç¼©
 */
async function shouldPerformCompression(): Promise<boolean> {
  const result = await sql`
    SELECT
      last_check_time,
      EXTRACT(EPOCH FROM (NOW() - last_check_time)) * 1000 as time_diff_ms
    FROM compression_state
    WHERE id = 1
  `

  if (result.length === 0) {
    return true // å¦‚æœæ²¡æœ‰è®°å½•ï¼Œæ‰§è¡Œå‹ç¼©
  }

  const timeDiff = parseFloat(result[0].time_diff_ms || '0')
  return timeDiff >= COMPRESSION_INTERVAL
}

/**
 * æ›´æ–°å‹ç¼©çŠ¶æ€
 */
async function updateCompressionState(): Promise<void> {
  await sql`
    UPDATE compression_state
    SET
      last_check_time = CURRENT_TIMESTAMP,
      last_compression_time = CURRENT_TIMESTAMP,
      updated_at = CURRENT_TIMESTAMP
    WHERE id = 1
  `
}

/**
 * ç¡®ä¿å‹ç¼©è¡¨å­˜åœ¨
 */
async function ensureCompressionTableExists(): Promise<void> {
  await sql`
    CREATE TABLE IF NOT EXISTS onenet_data_compressed (
      id SERIAL PRIMARY KEY,
      device_id VARCHAR(50),
      datastream_id VARCHAR(100),
      avg_value NUMERIC,
      min_value NUMERIC,
      max_value NUMERIC,
      sample_count INTEGER,
      time_bucket TIMESTAMP,
      created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
      UNIQUE(device_id, datastream_id, time_bucket)
    )
  `
  
  // åˆ›å»ºç´¢å¼•ä»¥æé«˜æŸ¥è¯¢æ€§èƒ½
  await sql`
    CREATE INDEX IF NOT EXISTS idx_compressed_device_datastream_time 
    ON onenet_data_compressed (device_id, datastream_id, time_bucket)
  `
}

/**
 * å‹ç¼©æŒ‡å®šæ—¶é—´ä¹‹å‰çš„æ•°æ®
 */
async function compressDataBefore(beforeTime: Date): Promise<{ compressedRows: number, deletedRows: number }> {
  // æŒ‰5åˆ†é’Ÿé—´éš”å‹ç¼©æ•°æ®
  const compressResult = await sql`
    INSERT INTO onenet_data_compressed (
      device_id, datastream_id, avg_value, min_value, max_value, 
      sample_count, time_bucket
    )
    SELECT 
      device_id,
      datastream_id,
      AVG(CAST(value AS NUMERIC)) as avg_value,
      MIN(CAST(value AS NUMERIC)) as min_value,
      MAX(CAST(value AS NUMERIC)) as max_value,
      COUNT(*) as sample_count,
      -- ä¿®å¤æ—¶é—´åˆ†æ¡¶ï¼šæ­£ç¡®çš„5åˆ†é’Ÿå¯¹é½
      date_trunc('hour', created_at) +
      INTERVAL '5 minutes' * FLOOR(EXTRACT(minute FROM created_at) / 5) as time_bucket
    FROM onenet_data 
    WHERE created_at < ${beforeTime.toISOString()}
      AND created_at > ${new Date(beforeTime.getTime() - 60 * 60 * 1000).toISOString()} -- åªå¤„ç†1å°æ—¶å†…çš„æ•°æ®
    GROUP BY device_id, datastream_id, time_bucket
    ON CONFLICT (device_id, datastream_id, time_bucket) 
    DO UPDATE SET
      avg_value = EXCLUDED.avg_value,
      min_value = EXCLUDED.min_value,
      max_value = EXCLUDED.max_value,
      sample_count = EXCLUDED.sample_count
  `
  
  // åˆ é™¤å·²å‹ç¼©çš„åŸå§‹æ•°æ®
  const deleteResult = await sql`
    DELETE FROM onenet_data 
    WHERE created_at < ${beforeTime.toISOString()}
      AND created_at > ${new Date(beforeTime.getTime() - 60 * 60 * 1000).toISOString()}
  `
  
  return {
    compressedRows: compressResult.length || 0,
    deletedRows: deleteResult.length || 0
  }
}

/**
 * è·å–å‹ç¼©ç»Ÿè®¡ä¿¡æ¯
 */
export async function getCompressionStats(): Promise<{
  originalRecords: number
  compressedRecords: number
  lastCompressionTime: Date | null
  nextCompressionTime: Date
}> {
  try {
    // è·å–åŸå§‹æ•°æ®è®°å½•æ•°
    const originalCount = await sql`SELECT COUNT(*) as count FROM onenet_data`
    
    // è·å–å‹ç¼©æ•°æ®è®°å½•æ•°
    const compressedCount = await sql`
      SELECT COUNT(*) as count FROM onenet_data_compressed 
      WHERE created_at IS NOT NULL
    `
    
    // è·å–å‹ç¼©çŠ¶æ€
    const stateResult = await sql`
      SELECT last_check_time FROM compression_state WHERE id = 1
    `

    // è®¡ç®—ä¸‹æ¬¡å‹ç¼©æ—¶é—´
    const lastCheckTime = stateResult[0]?.last_check_time
      ? new Date(stateResult[0].last_check_time).getTime()
      : Date.now()
    const nextCompressionTime = new Date(lastCheckTime + COMPRESSION_INTERVAL)
    
    // è·å–æœ€åå‹ç¼©æ—¶é—´
    const lastCompressed = await sql`
      SELECT MAX(created_at) as last_time FROM onenet_data_compressed
    `
    
    return {
      originalRecords: parseInt(originalCount[0].count),
      compressedRecords: parseInt(compressedCount[0].count),
      lastCompressionTime: lastCompressed[0].last_time ? new Date(lastCompressed[0].last_time) : null,
      nextCompressionTime
    }
  } catch (error) {
    console.error('è·å–å‹ç¼©ç»Ÿè®¡å¤±è´¥:', error)
    return {
      originalRecords: 0,
      compressedRecords: 0,
      lastCompressionTime: null,
      nextCompressionTime: new Date()
    }
  }
}

/**
 * æ‰‹åŠ¨è§¦å‘å‹ç¼©ï¼ˆç”¨äºæµ‹è¯•ï¼‰
 */
export async function manualCompress(): Promise<CompressionResult> {
  // é‡ç½®æ£€æŸ¥æ—¶é—´ï¼Œå¼ºåˆ¶æ‰§è¡Œå‹ç¼©
  await sql`
    UPDATE compression_state
    SET last_check_time = CURRENT_TIMESTAMP - INTERVAL '1 hour'
    WHERE id = 1
  `
  return await checkAndCompress()
}
